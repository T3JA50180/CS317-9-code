{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-04T09:44:48.415751Z",
     "start_time": "2024-11-04T09:44:44.280729Z"
    }
   },
   "outputs": [],
   "source": [
    "from utils import *\n",
    "device = 'cuda:0'\n",
    "model_name = 'AlexNet'\n",
    "output_file = f'model_saves/{model_name}.txt'\n",
    "sys.stdout = open(output_file, \"w\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f3b3d9428060f7d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "60e749410050429dbbd3b0576fc90875",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "BATCH_SIZE = 128\n",
    "NUM_EPOCHS = 30\n",
    "\n",
    "train_dataloader, test_dataloader = dataloader(pin_memory=True, num_workers=16)\n",
    "model = models.alexnet(pretrained=True)\n",
    "model.classifier = nn.Sequential(\n",
    "    nn.Linear(in_features=9216, out_features=12, bias=True)\n",
    ")\n",
    "\n",
    "for parameter in model.features.parameters():\n",
    "    parameter.requires_grad = False\n",
    "\n",
    "model = model.to(device)\n",
    "\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.1, momentum=0.9)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.5)\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "accuracy_fn = torchmetrics.classification.Accuracy(num_classes=12).to(device)\n",
    "\n",
    "\n",
    "start_time = timer()\n",
    "\n",
    "model_results = train(\n",
    "    device,\n",
    "    model,\n",
    "    train_dataloader,\n",
    "    test_dataloader,\n",
    "    optimizer,\n",
    "    loss_fn,\n",
    "    accuracy_fn,\n",
    "    NUM_EPOCHS,\n",
    "    model_name,\n",
    "    scheduler)\n",
    "\n",
    "end_time = timer()\n",
    "\n",
    "print(f'Total training time: {end_time - start_time:.3f} seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2166eaef1582e0c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'model_saves/{model_name}.pkl', 'wb') as f:\n",
    "    pickle.dump(model_results, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a5117c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Epoch:  0 | Train_Loss: 0.9271 |  Train_Acc: 0.7491 |  Test Loss: 0.6593 |  Test Acc: 0.8348 |  Time: 95.6975 seconds\n",
    "# Epoch:  1 | Train_Loss: 0.5862 |  Train_Acc: 0.8516 |  Test Loss: 0.5361 |  Test Acc: 0.8658 |  Time: 96.0922 seconds\n",
    "# Epoch:  2 | Train_Loss: 0.4944 |  Train_Acc: 0.8858 |  Test Loss: 0.4646 |  Test Acc: 0.9010 |  Time: 101.4636 seconds\n",
    "# Epoch:  3 | Train_Loss: 0.4378 |  Train_Acc: 0.9019 |  Test Loss: 0.4197 |  Test Acc: 0.9080 |  Time: 110.3106 seconds\n",
    "# Epoch:  4 | Train_Loss: 0.3986 |  Train_Acc: 0.9116 |  Test Loss: 0.3911 |  Test Acc: 0.9062 |  Time: 107.0428 seconds\n",
    "# Epoch:  5 | Train_Loss: 0.3691 |  Train_Acc: 0.9181 |  Test Loss: 0.3647 |  Test Acc: 0.9141 |  Time: 109.0730 seconds\n",
    "# Epoch:  6 | Train_Loss: 0.3463 |  Train_Acc: 0.9219 |  Test Loss: 0.3412 |  Test Acc: 0.9241 |  Time: 122.6566 seconds\n",
    "# Epoch:  7 | Train_Loss: 0.3280 |  Train_Acc: 0.9256 |  Test Loss: 0.3252 |  Test Acc: 0.9233 |  Time: 118.1782 seconds\n",
    "# Epoch:  8 | Train_Loss: 0.3124 |  Train_Acc: 0.9284 |  Test Loss: 0.3122 |  Test Acc: 0.9283 |  Time: 114.5437 seconds\n",
    "# Epoch:  9 | Train_Loss: 0.2992 |  Train_Acc: 0.9302 |  Test Loss: 0.2996 |  Test Acc: 0.9285 |  Time: 110.5902 seconds\n",
    "# Epoch: 10 | Train_Loss: 0.2882 |  Train_Acc: 0.9322 |  Test Loss: 0.2887 |  Test Acc: 0.9297 |  Time: 96.9368 seconds\n",
    "# Epoch: 11 | Train_Loss: 0.2783 |  Train_Acc: 0.9338 |  Test Loss: 0.2813 |  Test Acc: 0.9312 |  Time: 121.4178 seconds\n",
    "# Epoch: 12 | Train_Loss: 0.2695 |  Train_Acc: 0.9353 |  Test Loss: 0.2729 |  Test Acc: 0.9319 |  Time: 117.0241 seconds\n",
    "# Epoch: 13 | Train_Loss: 0.2619 |  Train_Acc: 0.9364 |  Test Loss: 0.2652 |  Test Acc: 0.9347 |  Time: 102.0895 seconds\n",
    "# Epoch: 14 | Train_Loss: 0.2547 |  Train_Acc: 0.9381 |  Test Loss: 0.2576 |  Test Acc: 0.9358 |  Time: 98.5325 seconds\n",
    "# Epoch: 15 | Train_Loss: 0.2483 |  Train_Acc: 0.9389 |  Test Loss: 0.2530 |  Test Acc: 0.9370 |  Time: 111.5510 seconds\n",
    "# Epoch: 16 | Train_Loss: 0.2425 |  Train_Acc: 0.9402 |  Test Loss: 0.2494 |  Test Acc: 0.9368 |  Time: 108.8764 seconds\n",
    "# Epoch: 17 | Train_Loss: 0.2372 |  Train_Acc: 0.9410 |  Test Loss: 0.2428 |  Test Acc: 0.9381 |  Time: 103.8908 seconds\n",
    "# Epoch: 18 | Train_Loss: 0.2323 |  Train_Acc: 0.9419 |  Test Loss: 0.2372 |  Test Acc: 0.9392 |  Time: 101.5395 seconds\n",
    "# Epoch: 19 | Train_Loss: 0.2278 |  Train_Acc: 0.9426 |  Test Loss: 0.2323 |  Test Acc: 0.9410 |  Time: 103.5721 seconds\n",
    "# Epoch: 20 | Train_Loss: 0.2235 |  Train_Acc: 0.9438 |  Test Loss: 0.2302 |  Test Acc: 0.9408 |  Time: 99.0276 seconds\n",
    "# Epoch: 21 | Train_Loss: 0.2196 |  Train_Acc: 0.9439 |  Test Loss: 0.2244 |  Test Acc: 0.9431 |  Time: 96.0393 seconds\n",
    "# Epoch: 22 | Train_Loss: 0.2159 |  Train_Acc: 0.9452 |  Test Loss: 0.2245 |  Test Acc: 0.9394 |  Time: 89.6598 seconds\n",
    "# Epoch: 23 | Train_Loss: 0.2124 |  Train_Acc: 0.9456 |  Test Loss: 0.2192 |  Test Acc: 0.9423 |  Time: 91.3244 seconds\n",
    "# Epoch: 24 | Train_Loss: 0.2092 |  Train_Acc: 0.9464 |  Test Loss: 0.2148 |  Test Acc: 0.9440 |  Time: 102.4942 seconds\n",
    "# Epoch: 25 | Train_Loss: 0.2060 |  Train_Acc: 0.9469 |  Test Loss: 0.2113 |  Test Acc: 0.9449 |  Time: 105.7312 seconds\n",
    "# Epoch: 26 | Train_Loss: 0.2032 |  Train_Acc: 0.9474 |  Test Loss: 0.2093 |  Test Acc: 0.9447 |  Time: 93.2069 seconds\n",
    "# Epoch: 27 | Train_Loss: 0.2005 |  Train_Acc: 0.9482 |  Test Loss: 0.2066 |  Test Acc: 0.9447 |  Time: 95.9400 seconds\n",
    "# Epoch: 28 | Train_Loss: 0.1977 |  Train_Acc: 0.9485 |  Test Loss: 0.2035 |  Test Acc: 0.9462 |  Time: 92.2666 seconds\n",
    "# Epoch: 29 | Train_Loss: 0.1952 |  Train_Acc: 0.9495 |  Test Loss: 0.2054 |  Test Acc: 0.9454 |  Time: 111.8197 seconds\n",
    "# Epoch: 30 | Train_Loss: 0.1929 |  Train_Acc: 0.9498 |  Test Loss: 0.1992 |  Test Acc: 0.9473 |  Time: 97.9497 seconds\n",
    "# Epoch: 31 | Train_Loss: 0.1906 |  Train_Acc: 0.9502 |  Test Loss: 0.1987 |  Test Acc: 0.9480 |  Time: 100.7533 seconds\n",
    "# Epoch: 32 | Train_Loss: 0.1885 |  Train_Acc: 0.9509 |  Test Loss: 0.1955 |  Test Acc: 0.9472 |  Time: 92.1560 seconds\n",
    "# Epoch: 33 | Train_Loss: 0.1863 |  Train_Acc: 0.9512 |  Test Loss: 0.1934 |  Test Acc: 0.9483 |  Time: 88.3805 seconds\n",
    "# Epoch: 34 | Train_Loss: 0.1843 |  Train_Acc: 0.9516 |  Test Loss: 0.1921 |  Test Acc: 0.9477 |  Time: 95.0290 seconds\n",
    "# Epoch: 35 | Train_Loss: 0.1824 |  Train_Acc: 0.9515 |  Test Loss: 0.1885 |  Test Acc: 0.9487 |  Time: 95.0904 seconds\n",
    "# Epoch: 36 | Train_Loss: 0.1806 |  Train_Acc: 0.9521 |  Test Loss: 0.1878 |  Test Acc: 0.9494 |  Time: 100.3355 seconds\n",
    "# Epoch: 37 | Train_Loss: 0.1787 |  Train_Acc: 0.9528 |  Test Loss: 0.1862 |  Test Acc: 0.9506 |  Time: 98.0543 seconds\n",
    "# Epoch: 38 | Train_Loss: 0.1772 |  Train_Acc: 0.9526 |  Test Loss: 0.1857 |  Test Acc: 0.9498 |  Time: 110.3760 seconds\n",
    "# Epoch: 39 | Train_Loss: 0.1754 |  Train_Acc: 0.9532 |  Test Loss: 0.1821 |  Test Acc: 0.9509 |  Time: 103.8881 seconds\n",
    "# Epoch: 40 | Train_Loss: 0.1737 |  Train_Acc: 0.9537 |  Test Loss: 0.1809 |  Test Acc: 0.9515 |  Time: 97.3479 seconds\n",
    "# Epoch: 41 | Train_Loss: 0.1723 |  Train_Acc: 0.9540 |  Test Loss: 0.1816 |  Test Acc: 0.9498 |  Time: 89.0836 seconds\n",
    "# Epoch: 42 | Train_Loss: 0.1708 |  Train_Acc: 0.9545 |  Test Loss: 0.1783 |  Test Acc: 0.9521 |  Time: 88.8271 seconds\n",
    "# Epoch: 43 | Train_Loss: 0.1693 |  Train_Acc: 0.9544 |  Test Loss: 0.1761 |  Test Acc: 0.9522 |  Time: 89.6516 seconds\n",
    "# Epoch: 44 | Train_Loss: 0.1679 |  Train_Acc: 0.9549 |  Test Loss: 0.1747 |  Test Acc: 0.9527 |  Time: 90.9611 seconds\n",
    "# Epoch: 45 | Train_Loss: 0.1666 |  Train_Acc: 0.9551 |  Test Loss: 0.1745 |  Test Acc: 0.9517 |  Time: 95.1815 seconds\n",
    "# Epoch: 46 | Train_Loss: 0.1654 |  Train_Acc: 0.9554 |  Test Loss: 0.1740 |  Test Acc: 0.9521 |  Time: 92.1548 seconds\n",
    "# Epoch: 47 | Train_Loss: 0.1640 |  Train_Acc: 0.9558 |  Test Loss: 0.1719 |  Test Acc: 0.9534 |  Time: 90.7277 seconds\n",
    "# Epoch: 48 | Train_Loss: 0.1629 |  Train_Acc: 0.9559 |  Test Loss: 0.1697 |  Test Acc: 0.9537 |  Time: 93.1825 seconds\n",
    "# Epoch: 49 | Train_Loss: 0.1616 |  Train_Acc: 0.9562 |  Test Loss: 0.1702 |  Test Acc: 0.9525 |  Time: 89.8793 seconds\n",
    "# Epoch: 50 | Train_Loss: 0.1605 |  Train_Acc: 0.9566 |  Test Loss: 0.1672 |  Test Acc: 0.9538 |  Time: 93.2569 seconds\n",
    "# Epoch: 51 | Train_Loss: 0.1594 |  Train_Acc: 0.9569 |  Test Loss: 0.1675 |  Test Acc: 0.9535 |  Time: 92.9218 seconds\n",
    "# Epoch: 52 | Train_Loss: 0.1582 |  Train_Acc: 0.9569 |  Test Loss: 0.1663 |  Test Acc: 0.9534 |  Time: 92.3579 seconds\n",
    "# Epoch: 53 | Train_Loss: 0.1570 |  Train_Acc: 0.9576 |  Test Loss: 0.1652 |  Test Acc: 0.9540 |  Time: 92.1838 seconds\n",
    "# Epoch: 54 | Train_Loss: 0.1561 |  Train_Acc: 0.9576 |  Test Loss: 0.1640 |  Test Acc: 0.9545 |  Time: 95.5285 seconds\n",
    "# Epoch: 55 | Train_Loss: 0.1550 |  Train_Acc: 0.9578 |  Test Loss: 0.1624 |  Test Acc: 0.9558 |  Time: 93.4544 seconds\n",
    "# Epoch: 56 | Train_Loss: 0.1540 |  Train_Acc: 0.9582 |  Test Loss: 0.1619 |  Test Acc: 0.9542 |  Time: 93.3961 seconds\n",
    "# Epoch: 57 | Train_Loss: 0.1531 |  Train_Acc: 0.9580 |  Test Loss: 0.1604 |  Test Acc: 0.9555 |  Time: 97.1659 seconds\n",
    "# Epoch: 58 | Train_Loss: 0.1521 |  Train_Acc: 0.9584 |  Test Loss: 0.1601 |  Test Acc: 0.9564 |  Time: 96.2467 seconds\n",
    "# Epoch: 59 | Train_Loss: 0.1512 |  Train_Acc: 0.9590 |  Test Loss: 0.1586 |  Test Acc: 0.9565 |  Time: 93.3585 seconds\n",
    "# Epoch: 60 | Train_Loss: 0.1503 |  Train_Acc: 0.9588 |  Test Loss: 0.1575 |  Test Acc: 0.9569 |  Time: 91.8670 seconds\n",
    "# Epoch: 61 | Train_Loss: 0.1494 |  Train_Acc: 0.9592 |  Test Loss: 0.1587 |  Test Acc: 0.9564 |  Time: 86.6351 seconds\n",
    "# Epoch: 62 | Train_Loss: 0.1485 |  Train_Acc: 0.9593 |  Test Loss: 0.1559 |  Test Acc: 0.9575 |  Time: 84.8872 seconds\n",
    "# Epoch: 63 | Train_Loss: 0.1477 |  Train_Acc: 0.9595 |  Test Loss: 0.1555 |  Test Acc: 0.9575 |  Time: 83.6373 seconds\n",
    "# Epoch: 64 | Train_Loss: 0.1467 |  Train_Acc: 0.9602 |  Test Loss: 0.1541 |  Test Acc: 0.9572 |  Time: 86.3593 seconds\n",
    "# Epoch: 65 | Train_Loss: 0.1460 |  Train_Acc: 0.9597 |  Test Loss: 0.1539 |  Test Acc: 0.9568 |  Time: 84.7836 seconds\n",
    "# Epoch: 66 | Train_Loss: 0.1451 |  Train_Acc: 0.9599 |  Test Loss: 0.1532 |  Test Acc: 0.9576 |  Time: 87.8940 seconds\n",
    "# Epoch: 67 | Train_Loss: 0.1445 |  Train_Acc: 0.9607 |  Test Loss: 0.1528 |  Test Acc: 0.9569 |  Time: 91.4950 seconds\n",
    "# Epoch: 68 | Train_Loss: 0.1437 |  Train_Acc: 0.9604 |  Test Loss: 0.1519 |  Test Acc: 0.9581 |  Time: 89.9450 seconds\n",
    "# Epoch: 69 | Train_Loss: 0.1429 |  Train_Acc: 0.9605 |  Test Loss: 0.1511 |  Test Acc: 0.9584 |  Time: 95.0836 seconds\n",
    "# Epoch: 70 | Train_Loss: 0.1421 |  Train_Acc: 0.9613 |  Test Loss: 0.1497 |  Test Acc: 0.9589 |  Time: 106.6199 seconds\n",
    "# Epoch: 71 | Train_Loss: 0.1415 |  Train_Acc: 0.9610 |  Test Loss: 0.1498 |  Test Acc: 0.9589 |  Time: 94.9535 seconds\n",
    "# Epoch: 72 | Train_Loss: 0.1409 |  Train_Acc: 0.9613 |  Test Loss: 0.1489 |  Test Acc: 0.9582 |  Time: 98.0379 seconds\n",
    "# Epoch: 73 | Train_Loss: 0.1402 |  Train_Acc: 0.9613 |  Test Loss: 0.1479 |  Test Acc: 0.9598 |  Time: 98.1502 seconds\n",
    "# Epoch: 74 | Train_Loss: 0.1393 |  Train_Acc: 0.9613 |  Test Loss: 0.1477 |  Test Acc: 0.9584 |  Time: 91.8605 seconds\n",
    "# Epoch: 75 | Train_Loss: 0.1388 |  Train_Acc: 0.9617 |  Test Loss: 0.1475 |  Test Acc: 0.9576 |  Time: 100.5438 seconds\n",
    "# Epoch: 76 | Train_Loss: 0.1381 |  Train_Acc: 0.9618 |  Test Loss: 0.1457 |  Test Acc: 0.9603 |  Time: 95.3908 seconds\n",
    "# Epoch: 77 | Train_Loss: 0.1375 |  Train_Acc: 0.9619 |  Test Loss: 0.1455 |  Test Acc: 0.9600 |  Time: 92.9312 seconds\n",
    "# Epoch: 78 | Train_Loss: 0.1369 |  Train_Acc: 0.9621 |  Test Loss: 0.1451 |  Test Acc: 0.9594 |  Time: 94.3219 seconds\n",
    "# Epoch: 79 | Train_Loss: 0.1363 |  Train_Acc: 0.9625 |  Test Loss: 0.1443 |  Test Acc: 0.9604 |  Time: 94.1755 seconds\n",
    "# Epoch: 80 | Train_Loss: 0.1357 |  Train_Acc: 0.9626 |  Test Loss: 0.1433 |  Test Acc: 0.9601 |  Time: 93.6038 seconds"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
