{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {},
   "source": [
    "from utils import *\n",
    "mp.set_start_method(\"spawn\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "a6a6effe32bc33d",
   "metadata": {},
   "source": [
    "train_dataloader, test_dataloader = dataloader()\n",
    "model, loss_fn, accuracy_fn = model_loader('AlexNet_Unfreezed_Wdecay_v1_cv1')\n",
    "model.to(device)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "2e60585c9c3822d6",
   "metadata": {},
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, roc_curve, auc\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "def plot_confusion_matrix_and_metrics(model, data_loader, device, class_names, criterion):\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    all_probs = []\n",
    "    total_loss = 0\n",
    "\n",
    "    with torch.inference_mode():\n",
    "        for X, y in tqdm(data_loader):\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            y_pred = model(X)\n",
    "            loss = criterion(y_pred, y)\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            probs = torch.softmax(y_pred, dim=1)\n",
    "            _, preds = torch.max(y_pred, 1)\n",
    "            \n",
    "            all_probs.extend(probs.cpu().numpy())\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(y.cpu().numpy())\n",
    "\n",
    "    all_preds = np.array(all_preds)\n",
    "    all_labels = np.array(all_labels)\n",
    "    all_probs = np.array(all_probs)\n",
    "\n",
    "    accuracy = accuracy_score(all_labels, all_preds)\n",
    "    precision = precision_score(all_labels, all_preds, average='weighted')\n",
    "    recall = recall_score(all_labels, all_preds, average='weighted')\n",
    "    f1 = f1_score(all_labels, all_preds, average='weighted')\n",
    "\n",
    "    avg_loss = total_loss / len(data_loader)\n",
    "\n",
    "    print(f\"Loss: {avg_loss:.4f}\")\n",
    "    print(f\"Accuracy: {accuracy * 100:.2f}%\")\n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    print(f\"Recall (Sensitivity): {recall:.4f}\")\n",
    "    print(f\"F1 Score: {f1:.4f}\")\n",
    "\n",
    "    if len(class_names) > 2:\n",
    "        fpr = {}\n",
    "        tpr = {}\n",
    "        roc_auc = {}\n",
    "        for i in range(len(class_names)):\n",
    "            fpr[i], tpr[i], _ = roc_curve(all_labels == i, all_probs[:, i])\n",
    "            roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "        plt.figure(figsize=(10, 8))\n",
    "        for i in range(len(class_names)):\n",
    "            plt.plot(fpr[i], tpr[i], label=f'{class_names[i]} (AUC = {roc_auc[i]:.2f})')\n",
    "        \n",
    "        plt.plot([0, 1], [0, 1], 'k--', lw=2)\n",
    "        plt.xlim([0.0, 1.0])\n",
    "        plt.ylim([0.0, 1.05])\n",
    "        plt.xlabel('False Positive Rate')\n",
    "        plt.ylabel('True Positive Rate')\n",
    "        plt.title('ROC AUC Curve')\n",
    "        plt.legend(loc='lower right')\n",
    "        plt.savefig('roc_auc_curve_9010_cnn.png', bbox_inches='tight', dpi=300)\n",
    "        plt.show()\n",
    "\n",
    "class_names = test_dataloader.dataset.classes\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "plot_confusion_matrix_and_metrics(model, test_dataloader, device, class_names, criterion)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "3a83cde8b2a7006b",
   "metadata": {},
   "source": [
    "model.classifier = nn.Sequential()\n",
    "model"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "430b60a255af63fe",
   "metadata": {},
   "source": [
    "train_features, train_labels = extract_features(train_dataloader, model)\n",
    "test_features, test_labels = extract_features(test_dataloader, model)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "82a718d6d4e1ee70",
   "metadata": {},
   "source": [
    "train_labels.shape"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "3afd2d7f18a62284",
   "metadata": {},
   "source": [
    "h2o.init()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "ab7edf3e0af1feb6",
   "metadata": {},
   "source": [
    "train_features_np = train_features.cpu().numpy()\n",
    "train_labels_np = train_labels.cpu().numpy()\n",
    "\n",
    "train_features_h2o = h2o.H2OFrame(train_features_np)\n",
    "train_labels_h2o = h2o.H2OFrame(train_labels_np, column_names=['label'])"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "4d393c02f9e0bf5a",
   "metadata": {},
   "source": [
    "lasso_model = H2OGeneralizedLinearEstimator(\n",
    "    family=\"gaussian\",\n",
    "    alpha=1.0,\n",
    "    lambda_=0.00000000000000000000001,\n",
    "    max_iterations=10000\n",
    ")\n",
    "start_time = timer()\n",
    "train_data_h2o = train_features_h2o.cbind(train_labels_h2o)\n",
    "lasso_model.train(\n",
    "    x=train_features_h2o.columns,\n",
    "    y='label',\n",
    "    training_frame=train_data_h2o\n",
    ")\n",
    "end_time = timer()\n",
    "print(f'Total training time: {end_time - start_time:.3f} seconds')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "3783495cd3f18fe7",
   "metadata": {},
   "source": [
    "coefficients = lasso_model.coef()\n",
    "first_key = next(iter(coefficients))\n",
    "del coefficients[first_key]\n",
    "non_zero_indices = [i for i, (key, value) in enumerate(coefficients.items()) if value != 0]\n",
    "\n",
    "len(non_zero_indices)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "5158c92ef2d37730",
   "metadata": {},
   "source": [
    "from timeit import default_timer as timer\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, roc_curve, auc\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "start_time = timer()\n",
    "\n",
    "coefficients = lasso_model.coef()\n",
    "first_key = next(iter(coefficients))\n",
    "del coefficients[first_key]\n",
    "non_zero_indices = [i for i, (key, value) in enumerate(coefficients.items()) if value != 0]\n",
    "\n",
    "train_features_selected = train_features\n",
    "test_features_selected = test_features\n",
    "\n",
    "xgb_model = XGBClassifier()\n",
    "xgb_model.fit(train_features_selected, train_labels)\n",
    "\n",
    "all_preds = xgb_model.predict(test_features_selected)\n",
    "all_probs = xgb_model.predict_proba(test_features_selected)\n",
    "accuracy = accuracy_score(test_labels, all_preds)\n",
    "\n",
    "all_preds = np.array(all_preds)\n",
    "all_labels = np.array(test_labels)\n",
    "\n",
    "cm = confusion_matrix(all_labels, all_preds)\n",
    "precision = precision_score(all_labels, all_preds, average='weighted')\n",
    "recall = recall_score(all_labels, all_preds, average='weighted')\n",
    "f1 = f1_score(all_labels, all_preds, average='weighted')\n",
    "\n",
    "end_time = timer()\n",
    "print(f'Total training time: {end_time - start_time:.3f} seconds')\n",
    "\n",
    "print(f\"Accuracy: {accuracy * 100:.2f}%\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1 Score: {f1:.4f}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "6d40f192791e4eb8",
   "metadata": {},
   "source": [],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
